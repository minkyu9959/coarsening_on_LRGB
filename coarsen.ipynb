{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def coarsening_node_feat(node_feat, c_source_node, c_target_node): # Idea...\n",
    "  node_feat = node_feat.tolist()\n",
    "  source_node_feat = node_feat[c_source_node]\n",
    "  target_node_feat = node_feat[c_target_node]\n",
    "  \n",
    "  new_node_feat = source_node_feat + target_node_feat\n",
    "  mark_del_node_feat = [-1]*len(new_node_feat)\n",
    "\n",
    "  node_feat[c_source_node] = mark_del_node_feat\n",
    "  node_feat[c_target_node] = mark_del_node_feat\n",
    "  node_feat.append(new_node_feat)\n",
    "  \n",
    "\n",
    "  node_feat = [item + [0] * (len(new_node_feat) - len(item)) for item in node_feat]\n",
    "  node_feat = np.array(node_feat)\n",
    "\n",
    "  return node_feat\n",
    "\n",
    "def coarsening_edge_attr(edge_index, edge_attr, c_source_node, c_target_node): # Idea...\n",
    "\n",
    "  c_edge_indices = np.where((edge_index[:, 0] == c_source_node) | (edge_index[:, 0] == c_target_node))[0]\n",
    "  target_node = edge_index[c_edge_indices, 1]\n",
    "  target_node_indices = [np.where(target_node == node)[0] for node in np.unique(target_node)]\n",
    "  \n",
    "  for node, indices in zip(np.unique(target_node), target_node_indices):\n",
    "    if len(c_edge_indices[indices]) > 1 :\n",
    "        edge_attr[c_edge_indices[indices]] = np.sum(edge_attr[c_edge_indices[indices]], axis=0)\n",
    "         \n",
    "  c_edge_indices = np.where((edge_index[:, 1] == c_source_node) | (edge_index[:, 1] == c_target_node))[0]\n",
    "  source_node = edge_index[c_edge_indices, 0]\n",
    "  source_node_indices = [np.where(source_node == node)[0] for node in np.unique(source_node)]\n",
    "\n",
    "  for node, indices in zip(np.unique(source_node), source_node_indices):\n",
    "    if len(c_edge_indices[indices]) > 1 :\n",
    "        edge_attr[c_edge_indices[indices]] = np.sum(edge_attr[c_edge_indices[indices]], axis=0)\n",
    "\n",
    "  return edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original edge_index \n",
      " [[0 0 1 2 3 3 3 3 4 4 4 5 5 5]\n",
      " [3 5 4 3 0 2 4 5 1 3 5 0 3 4]]\n"
     ]
    }
   ],
   "source": [
    "node_feat = np.array([[0,0,0,0],[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4],[5,5,5,5]])\n",
    "edge_index = np.array([[0,0,1,2,3,3,3,3,4,4,4,5,5,5],[3,5,4,3,0,2,4,5,1,3,5,0,3,4]])\n",
    "edge_attr = np.array([[1,0,2],[1,0,1],[3,0,1],[2,0,5],[1,0,2],[2,0,5],[6,0,1],[0,0,2],[3,0,1],[6,0,1],[4,0,5],[1,0,1],[0,0,2],[4,0,5]])\n",
    "\n",
    "r = 0.5\n",
    "\n",
    "print(\"Original edge_index \\n\",edge_index)\n",
    "\n",
    "num_edge = len(edge_index.T)\n",
    "edge_index = edge_index.T\n",
    "new_node = np.max(edge_index)\n",
    "coarsened_edge = np.sort(np.random.choice(range(0, num_edge), int(num_edge * r/2), replace = False))\n",
    "mark_del_edge_index = np.full(edge_index.shape[1], -1)\n",
    "mark_del_edge_feat = np.full(edge_attr.shape[1], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which edges will be deleted \n",
      " [ 2  9 12]\n"
     ]
    }
   ],
   "source": [
    "# Check whether coarsened_edge includes some two edges that are same in undirected graph\n",
    "# coarsened_edge = np.array([4, 6, 11])\n",
    "\n",
    "for idx_c_edge in range(len(coarsened_edge)):\n",
    "   \n",
    "  dup_edge = np.array([edge_index[coarsened_edge[idx_c_edge]][1], edge_index[coarsened_edge[idx_c_edge]][0]])\n",
    "  \n",
    "  for j in range(len(coarsened_edge)):\n",
    "    if j != idx_c_edge:\n",
    "             \n",
    "       if (edge_index[coarsened_edge[j]] == dup_edge).all():\n",
    "          coarsened_edge = np.delete(coarsened_edge, j)\n",
    "          break\n",
    "\n",
    "  if idx_c_edge+1 == len(coarsened_edge):\n",
    "    break\n",
    "\n",
    "print(\"Which edges will be deleted \\n\",coarsened_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change edge_index & node_feat\n",
    "\n",
    "for idx_c_edge in coarsened_edge:\n",
    "  \n",
    "  new_node += 1\n",
    "\n",
    "  if edge_index[idx_c_edge, 0] > edge_index[idx_c_edge, 1]:\n",
    "     c_source_node = edge_index[idx_c_edge, 1]\n",
    "     c_target_node = edge_index[idx_c_edge, 0]\n",
    "  else:\n",
    "     c_source_node = edge_index[idx_c_edge, 0]\n",
    "     c_target_node = edge_index[idx_c_edge, 1]\n",
    "  \n",
    "  if c_source_node == -1 or c_target_node == -1:\n",
    "    continue\n",
    "\n",
    "  node_feat = coarsening_node_feat(node_feat, c_source_node, c_target_node)\n",
    "\n",
    "  # Updating edge features for coarsened edges\n",
    "  edge_attr = coarsening_edge_attr(edge_index, edge_attr, c_source_node, c_target_node)\n",
    "  \n",
    "  # Replacing coarsened node index to new node index\n",
    "  mask_source = np.logical_or(edge_index[:, 0] == c_source_node, edge_index[:, 0] == c_target_node)\n",
    "  mask_target = np.logical_or(edge_index[:, 1] == c_source_node, edge_index[:, 1] == c_target_node)\n",
    "  edge_index[mask_source, 0] = new_node\n",
    "  edge_index[mask_target, 1] = new_node\n",
    "\n",
    "  # Marking deleted edge indices and features by [-1, -1] and [-1, -1, ... , -1]\n",
    "  mask_self_loop = edge_index[:, 0] == edge_index[:, 1]\n",
    "  edge_index[mask_self_loop] = mark_del_edge_index\n",
    "  edge_attr[mask_self_loop] = mark_del_edge_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_feat \n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 0 0 0 0 1 1 1 1 4 4 4 4]]\n",
      "edge_index \n",
      " [[0 2 8 8]\n",
      " [8 8 0 2]]\n",
      "edge_attr \n",
      " [[4 0 6]\n",
      " [2 0 5]\n",
      " [4 0 6]\n",
      " [2 0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Node feature part\n",
    "\n",
    "rows_to_delete = np.where(node_feat[:, 0] == -1) \n",
    "node_feat = np.delete(node_feat, rows_to_delete, axis=0) # Delete [-1, ... , -1]\n",
    "\n",
    "# Edge feature part\n",
    "\n",
    "edge_dict = {}\n",
    "for i, edge in enumerate(edge_index):\n",
    "    key = tuple(edge)\n",
    "    if key in edge_dict:\n",
    "        if np.all(edge_attr[edge_dict[key]] == mark_del_edge_feat):\n",
    "            continue\n",
    "        else:\n",
    "            edge_attr[edge_dict[key]] += edge_attr[i]\n",
    "    else:\n",
    "        edge_dict[key] = i\n",
    "unique_edge_attr = edge_attr[list(edge_dict.values())] # Aggregate edge features\n",
    "edge_attr = unique_edge_attr[~np.all(unique_edge_attr == mark_del_edge_feat, axis = 1)] # Delete [-1, ... -1]\n",
    "\n",
    "rows_to_delete = np.where(np.all(edge_index == mark_del_edge_index, axis=1))\n",
    "edge_index = np.delete(edge_index, rows_to_delete, axis=0) # Delete [-1, -1]\n",
    "edge_index, unique_indices = np.unique(edge_index, return_index=True, axis = 0) # Delete duplicated node pairs\n",
    "edge_index = edge_index[np.argsort(unique_indices)].T\n",
    "\n",
    "print(\"node_feat \\n\",node_feat)\n",
    "print(\"edge_index \\n\",edge_index)\n",
    "print(\"edge_attr \\n\",edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final node_feat \n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 0 0 0 0 1 1 1 1 4 4 4 4]]\n",
      "Final edge_index \n",
      " [[0 1 2 2]\n",
      " [2 2 0 1]]\n",
      "Final edge_attr \n",
      " [[4 0 6]\n",
      " [2 0 5]\n",
      " [4 0 6]\n",
      " [2 0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Reindex edge_index\n",
    "\n",
    "flattened_edge_index = edge_index.flatten()\n",
    "unique_elements = np.unique(flattened_edge_index)\n",
    "element_mapping = {element: new_value for new_value, element in enumerate(unique_elements)}\n",
    "edge_index = np.vectorize(element_mapping.get)(edge_index)\n",
    "\n",
    "print(\"Final node_feat \\n\",node_feat)\n",
    "print(\"Final edge_index \\n\",edge_index)\n",
    "print(\"Final edge_attr \\n\",edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Edge Index:\n",
      "[[0 0 1 2 3 3 3 3 4 4 4 5 5 5]\n",
      " [3 5 4 3 0 2 4 5 1 3 5 0 3 4]]\n",
      "\n",
      "Coarsened Edge Index:\n",
      "[[3, 3], [4, 4], [0, 5], [1, 5], [4, 3]]\n",
      "\n",
      "Restored Edge Index:\n",
      "[[10, -1], [-1, -1], [10, -1], [-1, -1], [-1, -1], [-1, -1], [8, -1], [-1, -1], [6, -1], [-1, -1], [2, -1], [-1, -1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, num_nodes, edge_index):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "def coarsen_graph(graph):\n",
    "    # Simplified coarsening: Merge pairs of nodes into super-nodes\n",
    "    num_coarsened_nodes = graph.num_nodes // 2\n",
    "    coarsened_edge_index = [[-1, -1] for _ in range(num_coarsened_nodes * 2)]\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(graph.edge_index[0]):\n",
    "        source1, target1 = graph.edge_index[0][i], graph.edge_index[1][i]\n",
    "        \n",
    "        if source1 != -1:\n",
    "            source2, target2 = graph.edge_index[0][i+1], graph.edge_index[1][i+1]\n",
    "            if source2 != -1:\n",
    "                if coarsened_edge_index[source1][0] == -1:\n",
    "                    coarsened_edge_index[source1][0] = target1\n",
    "                else:\n",
    "                    coarsened_edge_index[source1][1] = target1\n",
    "                \n",
    "                if coarsened_edge_index[target1][0] == -1:\n",
    "                    coarsened_edge_index[target1][0] = source1\n",
    "                else:\n",
    "                    coarsened_edge_index[target1][1] = source1\n",
    "                \n",
    "                i += 2\n",
    "            else:\n",
    "                coarsened_edge_index[source1][0] = target1\n",
    "                coarsened_edge_index[target1][0] = source1\n",
    "                i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    # Remove duplicate connections\n",
    "    unique_coarsened_edge_index = []\n",
    "    for i in range(num_coarsened_nodes * 2):\n",
    "        if coarsened_edge_index[i][0] != -1:\n",
    "            unique_coarsened_edge_index.append(coarsened_edge_index[i])\n",
    "    \n",
    "    return Graph(num_coarsened_nodes, unique_coarsened_edge_index)\n",
    "\n",
    "def uncoarsen_graph(coarsened_graph, fine_graph):\n",
    "    # Upscale the coarsened graph to the fine graph\n",
    "    num_fine_nodes = fine_graph.num_nodes\n",
    "    fine_edge_index = [[-1, -1] for _ in range(num_fine_nodes * 2)]\n",
    "    \n",
    "    for i in range(len(coarsened_graph.edge_index)):\n",
    "        source, target = coarsened_graph.edge_index[i]\n",
    "        \n",
    "        if source != -1:\n",
    "            source *= 2\n",
    "            target *= 2\n",
    "            \n",
    "            fine_edge_index[source][0] = target\n",
    "            fine_edge_index[target][0] = source\n",
    "    \n",
    "    return Graph(num_fine_nodes, fine_edge_index)\n",
    "\n",
    "# Example edge_index representing pairs of edges\n",
    "edge_index = np.array([\n",
    "    [0, 0, 1, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
    "    [3, 5, 4, 3, 0, 2, 4, 5, 1, 3, 5, 0, 3, 4]\n",
    "])\n",
    "\n",
    "original_graph = Graph(6, edge_index)\n",
    "\n",
    "# Coarsen the original graph\n",
    "coarsened_graph = coarsen_graph(original_graph)\n",
    "\n",
    "# Uncoarsen the coarsened graph back to the original graph\n",
    "restored_graph = uncoarsen_graph(coarsened_graph, original_graph)\n",
    "\n",
    "# Print the edge_index of the original and restored graphs\n",
    "print(\"Original Edge Index:\")\n",
    "print(original_graph.edge_index)\n",
    "\n",
    "print(\"\\nCoarsened Edge Index:\")\n",
    "print(coarsened_graph.edge_index)\n",
    "\n",
    "print(\"\\nRestored Edge Index:\")\n",
    "print(restored_graph.edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrgb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
