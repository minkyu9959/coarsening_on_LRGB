{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def coarsening_node_feat(node_feat, source, target): # Idea...\n",
    "  source_node_feat = node_feat[source]\n",
    "  target_node_feat = node_feat[target]\n",
    "  return source_node_feat + target_node_feat\n",
    "\n",
    "def coarsening_edge_attr(edge_list): # Idea...\n",
    "  \n",
    "  return edge_list.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original edge_index \n",
      " [[0 0 1 2 3 3 3 3 4 4 4 5 5 5]\n",
      " [3 5 4 3 0 2 4 5 1 3 5 0 3 4]]\n"
     ]
    }
   ],
   "source": [
    "node_feat = np.array([[0,0,0,0],[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4],[5,5,5,5]])\n",
    "edge_index = np.array([[0,0,1,2,3,3,3,3,4,4,4,5,5,5],[3,5,4,3,0,2,4,5,1,3,5,0,3,4]])\n",
    "edge_attr = np.array([[1,0,2],[1,0,1],[3,0,1],[2,0,5],[1,0,2],[2,0,5],[6,0,1],[5,0,8],[3,0,1],[6,0,1],[4,0,5],[1,0,1],[0,0,2],[4,0,5]])\n",
    "\n",
    "r = 0.5\n",
    "\n",
    "print(\"Original edge_index \\n\",edge_index)\n",
    "\n",
    "num_edge = len(edge_index.T)\n",
    "edge_index = edge_index.T\n",
    "new_node = np.max(edge_index)\n",
    "coarsened_edge = np.sort(np.random.choice(range(0, num_edge), int(num_edge * r/2), replace = False))\n",
    "mark_del_node_feat = np.full(node_feat.shape[1], -1)\n",
    "mark_del_edge_index = np.full(edge_index.shape[1], -1)\n",
    "mark_del_edge_feat = np.full(edge_attr.shape[1], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which edges will be deleted \n",
      " [ 5  8 13]\n"
     ]
    }
   ],
   "source": [
    "# Check whether coarsened_edge includes some two edges that are same in undirected graph\n",
    "\n",
    "for idx_c_edge in range(len(coarsened_edge)):\n",
    "   \n",
    "  dup_edge = np.array([edge_index[coarsened_edge[idx_c_edge]][1], edge_index[coarsened_edge[idx_c_edge]][0]])\n",
    "  \n",
    "  for j in range(len(coarsened_edge)):\n",
    "    if j != idx_c_edge:\n",
    "             \n",
    "       if (edge_index[coarsened_edge[j]] == dup_edge).all():\n",
    "          coarsened_edge = np.delete(coarsened_edge, j)\n",
    "          break\n",
    "\n",
    "  if idx_c_edge+1 == len(coarsened_edge):\n",
    "    break\n",
    "\n",
    "print(\"Which edges will be deleted \\n\",coarsened_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change edge_index & node_feat\n",
    "\n",
    "for idx_c_edge in coarsened_edge:\n",
    "  \n",
    "  new_node += 1\n",
    "\n",
    "  c_source_node = edge_index[idx_c_edge, 0]\n",
    "  c_target_node = edge_index[idx_c_edge, 1]\n",
    "\n",
    "  # print(\"target edge : \", [c_source_node, c_target_node])\n",
    "  if c_source_node == -1 or c_target_node == -1:\n",
    "    continue\n",
    "\n",
    "  new_node_feat = coarsening_node_feat(node_feat, c_source_node, c_target_node)\n",
    "  \n",
    "  # Marking deleted node features by -1 array\n",
    "  node_feat[c_source_node] = mark_del_node_feat\n",
    "  node_feat[c_target_node] = mark_del_node_feat\n",
    "  node_feat = np.vstack((node_feat, new_node_feat))\n",
    "  \n",
    "  # Replacing coarsened node index to new node index\n",
    "  mask_source = np.logical_or(edge_index[:, 0] == c_source_node, edge_index[:, 0] == c_target_node)\n",
    "  mask_target = np.logical_or(edge_index[:, 1] == c_source_node, edge_index[:, 1] == c_target_node)\n",
    "  edge_index[mask_source, 0] = new_node\n",
    "  edge_index[mask_target, 1] = new_node\n",
    "\n",
    "  # Updating edge features for coarsened edges\n",
    "  edge_attr[mask_source] = coarsening_edge_attr(edge_attr[mask_source])\n",
    "  edge_attr[mask_target] = coarsening_edge_attr(edge_attr[mask_target])\n",
    "\n",
    "  # Marking deleted edge indices and features by [-1, -1] and [-1, -1, ... , -1]\n",
    "  mask_self_loop = edge_index[:, 0] == edge_index[:, 1]\n",
    "  edge_index[mask_self_loop] = mark_del_edge_index\n",
    "  edge_attr[mask_self_loop] = mark_del_edge_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_feat \n",
      " [[ 0  0  0  0]\n",
      " [ 5  5  5  5]\n",
      " [10 10 10 10]]\n",
      "edge_index \n",
      " [[0 0 6 6 8 8]\n",
      " [6 8 0 8 0 6]]\n",
      "edge_attr \n",
      " [[  39    0   47]\n",
      " [ 647    0  736]\n",
      " [  16    0   21]\n",
      " [1294    0 1472]\n",
      " [ 512    0  580]\n",
      " [ 256    0  290]]\n"
     ]
    }
   ],
   "source": [
    "# Node feature part\n",
    "\n",
    "rows_to_delete = np.where(np.all(node_feat == mark_del_node_feat, axis=1)) \n",
    "node_feat = np.delete(node_feat, rows_to_delete, axis=0) # Delete [-1, ... , -1]\n",
    "\n",
    "# Edge feature part\n",
    "\n",
    "edge_dict = {}\n",
    "for i, edge in enumerate(edge_index):\n",
    "    key = tuple(edge)\n",
    "    if key in edge_dict:\n",
    "        if np.all(edge_attr[edge_dict[key]] == mark_del_edge_feat):\n",
    "            continue\n",
    "        else:\n",
    "            edge_attr[edge_dict[key]] += edge_attr[i]\n",
    "    else:\n",
    "        edge_dict[key] = i\n",
    "unique_edge_attr = edge_attr[list(edge_dict.values())] # Aggregate edge features\n",
    "edge_attr = unique_edge_attr[~np.all(unique_edge_attr == mark_del_edge_feat, axis = 1)] # Delete [-1, ... -1]\n",
    "\n",
    "rows_to_delete = np.where(np.all(edge_index == mark_del_edge_index, axis=1))\n",
    "edge_index = np.delete(edge_index, rows_to_delete, axis=0) # Delete [-1, -1]\n",
    "edge_index = np.unique(edge_index, axis = 0).T # Delete duplicated node pairs\n",
    "\n",
    "print(\"node_feat \\n\",node_feat)\n",
    "print(\"edge_index \\n\",edge_index)\n",
    "print(\"edge_attr \\n\",edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final node_feat \n",
      " [[ 0  0  0  0]\n",
      " [ 5  5  5  5]\n",
      " [10 10 10 10]]\n",
      "Final edge_index \n",
      " [[0 0 1 1 2 2]\n",
      " [1 2 0 2 0 1]]\n",
      "Final edge_attr \n",
      " [[  39    0   47]\n",
      " [ 647    0  736]\n",
      " [  16    0   21]\n",
      " [1294    0 1472]\n",
      " [ 512    0  580]\n",
      " [ 256    0  290]]\n"
     ]
    }
   ],
   "source": [
    "# Reindex edge_index\n",
    "\n",
    "flattened_edge_index = edge_index.flatten()\n",
    "unique_elements = np.unique(flattened_edge_index)\n",
    "element_mapping = {element: new_value for new_value, element in enumerate(unique_elements)}\n",
    "edge_index = np.vectorize(element_mapping.get)(edge_index)\n",
    "\n",
    "print(\"Final node_feat \\n\",node_feat)\n",
    "print(\"Final edge_index \\n\",edge_index)\n",
    "print(\"Final edge_attr \\n\",edge_attr)\n",
    "\n",
    "assert (len(edge_attr) == edge_index.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrgb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
